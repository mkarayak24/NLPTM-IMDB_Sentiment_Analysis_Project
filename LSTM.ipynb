{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Fatih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fatih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fatih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Fatih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import textstat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "nltk.data.path.append('C:\\\\Users\\\\Fatih\\\\Desktop\\\\EDU\\\\NLP\\\\NLTK')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('IMDB_Dataset.csv') \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W|\\d', ' ', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatizing\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to numeric values: 1 for positive, 0 for negative\n",
    "df['sentiment_numeric'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "\n",
    "def evaluate_model_lstm(true_labels, predicted_probs, threshold=0.5):\n",
    "    # Convert predicted probabilities to binary labels\n",
    "    predicted_labels = (predicted_probs >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=1)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM deneme for BoW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_bow_unigram = CountVectorizer(max_features=3000)\n",
    "\n",
    "X_bow_unigram = vectorizer_bow_unigram.fit_transform(df['cleaned_review']).toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow_unigram, df['sentiment_numeric'], test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# LSTM model:\n",
    "lstm_model_bow = Sequential()\n",
    "lstm_model_bow.add(Embedding(input_dim=5000, output_dim=128, input_length=X_train.shape[1])) \n",
    "\n",
    "#lstm_model_bow.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "# lstm_model_bow.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model_bow.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.0))  # Set recurrent_dropout to 0\n",
    "\n",
    "lstm_model_bow.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model_bow.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#lstm_model_bow.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "lstm_model_bow.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "\n",
    "print(\"LSTM with BoW:\")\n",
    "evaluate_model_lstm(y_test, lstm_model_bow.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHC SUGGESTION\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_model_lstm(true_labels, predicted_probs, threshold=0.5):\n",
    "    # Convert predicted probabilities to binary labels\n",
    "    predicted_labels = (predicted_probs >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label=1)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_bow_unigram = CountVectorizer(max_features=3000)\n",
    "X_bow_unigram = vectorizer_bow_unigram.fit_transform(df['cleaned_review']).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow_unigram, df['sentiment_numeric'], test_size=0.5, random_state=42)\n",
    "\n",
    "# LSTM model:\n",
    "lstm_model_bow = Sequential()\n",
    "lstm_model_bow.add(Embedding(input_dim=5000, output_dim=128, input_length=X_train.shape[1])) \n",
    "lstm_model_bow.add(LSTM(units=32, dropout=0.2, recurrent_dropout=0.0))  # Set recurrent_dropout to 0\n",
    "lstm_model_bow.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model_bow.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lstm_model_bow.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "print(\"LSTM with BoW:\")\n",
    "predicted_probs = lstm_model_bow.predict(X_test)\n",
    "evaluate_model_lstm(y_test, predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
