{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Keaton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Keaton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Keaton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Keaton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import textstat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('IMDB_Dataset.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Data Cleaning: Perform standard text preprocessing tasks, including: Removing stop words, punctuation, and special\n",
    "characters, Lowercasing the text, Tokenizing the reviews, Stemming or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W|\\d', ' ', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatizing\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALREADY DEFINED IN TASK 8\n",
    "# Function to print evaluation metrics\n",
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, pos_label='positive')\n",
    "    recall = recall_score(true_labels, predicted_labels, pos_label='positive')\n",
    "    f1 = f1_score(true_labels, predicted_labels, pos_label='positive')\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Unigram Feature Shape: (50000, 5000)\n",
      "TF-IDF Bigram Feature Shape: (50000, 5000)\n",
      "TF-IDF Trigram Feature Shape: (50000, 5000)\n",
      "Logistic Regression with TF-IDF using unigrams with 5000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.90\n",
      "F1-Score: 0.89\n",
      "Logistic Regression with TF-IDF using bigrams with 5000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.90\n",
      "F1-Score: 0.89\n",
      "Logistic Regression with TF-IDF using trigrams with 5000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.90\n",
      "F1-Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF PART 1\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_tfidf_unigram = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf_unigram = vectorizer_tfidf_unigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Bigram\n",
    "vectorizer_tfidf_bigram = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_tfidf_bigram = vectorizer_tfidf_bigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Trigram\n",
    "vectorizer_tfidf_trigram = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
    "X_tfidf_trigram = vectorizer_tfidf_trigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Özellik şekillerini kontrol etme\n",
    "print(\"TF-IDF Unigram Feature Shape:\", X_tfidf_unigram.shape)\n",
    "print(\"TF-IDF Bigram Feature Shape:\", X_tfidf_bigram.shape)\n",
    "print(\"TF-IDF Trigram Feature Shape:\", X_tfidf_trigram.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using unigrams with 5000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_bigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using bigrams with 5000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_trigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using trigrams with 5000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Unigram Feature Shape: (50000, 2500)\n",
      "TF-IDF Bigram Feature Shape: (50000, 2500)\n",
      "TF-IDF Trigram Feature Shape: (50000, 2500)\n",
      "Logistic Regression with TF-IDF using unigrams with 2500 features:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.88\n",
      "Recall: 0.90\n",
      "F1-Score: 0.89\n",
      "Logistic Regression with TF-IDF using bigrams with 2500 features:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.87\n",
      "Recall: 0.89\n",
      "F1-Score: 0.88\n",
      "Logistic Regression with TF-IDF using trigrams with 2500 features:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.88\n",
      "Recall: 0.90\n",
      "F1-Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF PART 2\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_tfidf_unigram = TfidfVectorizer(max_features=2500)\n",
    "X_tfidf_unigram = vectorizer_tfidf_unigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Bigram\n",
    "vectorizer_tfidf_bigram = TfidfVectorizer(max_features=2500, ngram_range=(1, 2))\n",
    "X_tfidf_bigram = vectorizer_tfidf_bigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Trigram\n",
    "vectorizer_tfidf_trigram = TfidfVectorizer(max_features=2500, ngram_range=(1, 3))\n",
    "X_tfidf_trigram = vectorizer_tfidf_trigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Özellik şekillerini kontrol etme\n",
    "print(\"TF-IDF Unigram Feature Shape:\", X_tfidf_unigram.shape)\n",
    "print(\"TF-IDF Bigram Feature Shape:\", X_tfidf_bigram.shape)\n",
    "print(\"TF-IDF Trigram Feature Shape:\", X_tfidf_trigram.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using unigrams with 2500 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_bigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using bigrams with 2500 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_trigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using trigrams with 2500 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Unigram Feature Shape: (50000, 10000)\n",
      "TF-IDF Bigram Feature Shape: (50000, 10000)\n",
      "TF-IDF Trigram Feature Shape: (50000, 10000)\n",
      "Logistic Regression with TF-IDF using unigrams with 10000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.89\n",
      "Recall: 0.91\n",
      "F1-Score: 0.90\n",
      "Logistic Regression with TF-IDF using bigrams with 10000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1-Score: 0.90\n",
      "Logistic Regression with TF-IDF using trigrams with 10000 features:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1-Score: 0.90\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF PART 3\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_tfidf_unigram = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf_unigram = vectorizer_tfidf_unigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Bigram\n",
    "vectorizer_tfidf_bigram = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf_bigram = vectorizer_tfidf_bigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Trigram\n",
    "vectorizer_tfidf_trigram = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
    "X_tfidf_trigram = vectorizer_tfidf_trigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Özellik şekillerini kontrol etme\n",
    "print(\"TF-IDF Unigram Feature Shape:\", X_tfidf_unigram.shape)\n",
    "print(\"TF-IDF Bigram Feature Shape:\", X_tfidf_bigram.shape)\n",
    "print(\"TF-IDF Trigram Feature Shape:\", X_tfidf_trigram.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using unigrams with 10000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_bigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using bigrams with 10000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_trigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using trigrams with 10000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Unigram Feature Shape: (50000, 1000)\n",
      "TF-IDF Bigram Feature Shape: (50000, 1000)\n",
      "TF-IDF Trigram Feature Shape: (50000, 1000)\n",
      "Logistic Regression with TF-IDF using unigrams with 1000 features:\n",
      "Accuracy: 0.86\n",
      "Precision: 0.86\n",
      "Recall: 0.88\n",
      "F1-Score: 0.87\n",
      "Logistic Regression with TF-IDF using bigrams with 1000 features:\n",
      "Accuracy: 0.86\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1-Score: 0.87\n",
      "Logistic Regression with TF-IDF using trigrams with 1000 features:\n",
      "Accuracy: 0.86\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1-Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF PART 3\n",
    "\n",
    "# Unigram (varsayılan)\n",
    "vectorizer_tfidf_unigram = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf_unigram = vectorizer_tfidf_unigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Bigram\n",
    "vectorizer_tfidf_bigram = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "X_tfidf_bigram = vectorizer_tfidf_bigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Trigram\n",
    "vectorizer_tfidf_trigram = TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
    "X_tfidf_trigram = vectorizer_tfidf_trigram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Özellik şekillerini kontrol etme\n",
    "print(\"TF-IDF Unigram Feature Shape:\", X_tfidf_unigram.shape)\n",
    "print(\"TF-IDF Bigram Feature Shape:\", X_tfidf_bigram.shape)\n",
    "print(\"TF-IDF Trigram Feature Shape:\", X_tfidf_trigram.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_unigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using unigrams with 1000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_bigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using bigrams with 1000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n",
    "\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_trigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using trigrams with 1000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['sentiment'], test_size=0.5, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf_tfidf = LogisticRegression(max_iter=1000)\n",
    "clf_tfidf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression model with tf-idf:\")\n",
    "evaluate_model(y_test, clf_tfidf.predict(X_test))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_trigram, df['sentiment'], test_size=0.2, random_state=42)\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with TF-IDF using trigrams with 10000 features:\")\n",
    "evaluate_model(y_test, clf.predict(X_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
